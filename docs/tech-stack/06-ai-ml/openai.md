# OpenAI GPT API

## ğŸ“š ä½¿ç”¨è¯´æ˜

é¡¹ç›®ä½¿ç”¨ OpenAI GPT æ¨¡å‹ä½œä¸ºæ ¸å¿ƒ AI å¼•æ“ï¼Œæä¾›æ™ºèƒ½å¯¹è¯å’Œæ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ã€‚

## ğŸ›  æ¡†æ¶é…ç½®

### å®‰è£…ä¾èµ–
```bash
pip install openai
```

### åŸºæœ¬é…ç½®
```python
import openai
from openai import OpenAI

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(api_key="your-api-key")

# åŸºæœ¬è°ƒç”¨
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹"},
        {"role": "user", "content": "ç”¨æˆ·æ¶ˆæ¯"}
    ],
    temperature=0.3,
    max_tokens=1000
)

assistant_message = response.choices[0].message.content
```


## ğŸ’» é¡¹ç›®åº”ç”¨

### æ•°å­—äººè®­ç»ƒæœåŠ¡
```python
# app/services/digital_human_training_service.py
class DigitalHumanTrainingService:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=settings.OPENAI_API_KEY,
            model="gpt-4o-mini",
            temperature=0.3
        )

    def _recognize_intent(self, state: TrainingState) -> Dict[str, Any]:
        prompt = f"""
        åˆ†æç”¨æˆ·æ¶ˆæ¯çš„æ„å›¾ï¼š
        å½“å‰ç”¨æˆ·æ¶ˆæ¯: {state['current_message']}

        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "intent": "information_sharing/question_asking/greeting",
            "stage": "initial/exploring/deepening"
        }}
        """

        response = self.llm.invoke([SystemMessage(content=prompt)])
        return json.loads(response.content)
```

### çŸ¥è¯†æŠ½å–æœåŠ¡
```python
# app/services/knowledge_extractor.py
class KnowledgeExtractor:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1)

    async def extract_entities_and_relations(self, text: str):
        prompt = f"""
        ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ï¼š
        æ–‡æœ¬ï¼š{text}

        è¯·è¿”å›JSONæ ¼å¼çš„ç»“æœ
        """

        response = self.llm.invoke([SystemMessage(content=prompt)])
        return json.loads(response.content)
```

### æµå¼å¯¹è¯æœåŠ¡
```python
# app/services/langgraph_service.py
class LangGraphService:
    def chat_stream(self, message: str, config: dict):
        prompt = self._build_chat_prompt(message, config)

        for chunk in self.llm.stream(prompt):
            if chunk.content:
                yield chunk.content
```


OpenAI GPT ä¸ºé¡¹ç›®æä¾›äº†æ ¸å¿ƒçš„ AI èƒ½åŠ›ï¼Œæ”¯æŒæ™ºèƒ½å¯¹è¯ã€æ„å›¾è¯†åˆ«å’ŒçŸ¥è¯†æŠ½å–åŠŸèƒ½ã€‚