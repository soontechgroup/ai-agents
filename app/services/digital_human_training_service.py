from typing import Dict, List, Any, Generator, Optional, AsyncGenerator, TypedDict, Annotated
import json
from datetime import datetime
from sqlalchemy.orm import Session
from langchain_openai import ChatOpenAI
from langchain.schema import BaseMessage, HumanMessage, SystemMessage
from langgraph.graph import StateGraph, END
import operator

from app.services.knowledge_extractor import KnowledgeExtractor
from app.services.graph_service import GraphService
from app.core.models import DigitalHumanTrainingMessage
from app.core.logger import logger
from app.core.config import settings


class TrainingState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]
    digital_human_id: int
    user_id: int
    current_message: str
    extracted_knowledge: Dict[str, Any]
    knowledge_context: Dict[str, Any]
    next_question: str
    should_extract: bool
    should_explore_deeper: bool
    conversation_stage: str
    total_knowledge_points: int
    categories: Dict[str, Any]
    current_step: str
    completed_steps: Annotated[List[str], operator.add]
    step_results: Dict[str, Any]
    thinking_process: Annotated[List[str], operator.add]
    events: Annotated[List[Dict[str, Any]], operator.add]  # äº‹ä»¶é˜Ÿåˆ—ï¼Œç”¨äºæµå¼é€šçŸ¥


class DigitalHumanTrainingService:
    
    def __init__(
        self,
        db: Session,
        knowledge_extractor: KnowledgeExtractor,
        graph_service: GraphService
    ):
        self.db = db
        self.knowledge_extractor = knowledge_extractor
        self.graph_service = graph_service
        
        self.llm = ChatOpenAI(
            api_key=settings.OPENAI_API_KEY,
            model="gpt-4o-mini",
            temperature=0.7
        )
        
        self.training_graph = self._build_training_graph()
    
    def _build_training_graph(self):
        workflow = StateGraph(TrainingState)
        
        workflow.add_node("intent_recognition", self._recognize_intent)
        workflow.add_node("knowledge_extraction", self._extract_knowledge)
        workflow.add_node("context_analysis", self._analyze_context)
        workflow.add_node("question_generation", self._generate_question)
        workflow.add_node("save_message", self._save_message)
        
        workflow.set_entry_point("intent_recognition")
        
        workflow.add_conditional_edges(
            "intent_recognition",
            self._route_after_intent,
            {
                "extract": "knowledge_extraction",
                "analyze": "context_analysis",
                "direct": "question_generation"
            }
        )
        
        workflow.add_edge("knowledge_extraction", "context_analysis")
        workflow.add_edge("context_analysis", "question_generation")
        workflow.add_edge("question_generation", "save_message")
        workflow.add_edge("save_message", END)
        
        return workflow.compile()
    
    def save_graph_visualization(self, output_dir: str = "graph_visualizations"):
        """ä¿å­˜å·¥ä½œæµå›¾çš„å¯è§†åŒ–"""
        from pathlib import Path
        
        Path(output_dir).mkdir(exist_ok=True)
        graph = self.training_graph.get_graph()
        
        # 1. å°è¯•ç”Ÿæˆ PNG å›¾ç‰‡
        png_path = f"{output_dir}/training_graph.png"
        try:
            graph.draw_png(output_file_path=png_path)
            logger.info(f"âœ… å›¾å·²ä¿å­˜ä¸º PNG: {png_path}")
            return png_path
        except Exception:
            logger.debug("PNG ç”Ÿæˆå¤±è´¥ï¼Œå°è¯• Mermaid æ ¼å¼")
        
        # 2. å¤‡é€‰æ–¹æ¡ˆï¼šä¿å­˜ Mermaid
        try:
            mermaid_path = f"{output_dir}/training_graph.mmd"
            Path(mermaid_path).write_text(graph.draw_mermaid())
            logger.info(f"âœ… å›¾å·²ä¿å­˜ä¸º Mermaid: {mermaid_path}")
            logger.info("ğŸ“Š å¯åœ¨ https://mermaid.live æŸ¥çœ‹")
            return mermaid_path
        except Exception as e:
            logger.error(f"âŒ æ— æ³•ç”Ÿæˆä»»ä½•å¯è§†åŒ–: {e}")
            return None
    
    def _recognize_intent(self, state: TrainingState) -> Dict[str, Any]:
        # èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
        events = [{
            "type": "node_start",
            "node": "intent_recognition",
            "message": "ğŸ” å¼€å§‹è¯†åˆ«ç”¨æˆ·æ„å›¾...",
            "timestamp": datetime.now().isoformat()
        }]
        
        current_step = "recognizing_intent"
        thinking_process = ["æ­£åœ¨è¯†åˆ«ç”¨æˆ·æ„å›¾..."]
        
        # æ·»åŠ æ€è€ƒæ­¥éª¤
        events.append({
            "type": "thinking",
            "node": "intent_recognition",
            "message": "ğŸ’­ åˆ†ææ¶ˆæ¯å†…å®¹ï¼Œè¯†åˆ«ç”¨æˆ·æ„å›¾...",
            "timestamp": datetime.now().isoformat()
        })
        
        prompt = f"""
åˆ†æä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯çš„æ„å›¾å’Œå†…å®¹ç±»å‹ï¼š

ç”¨æˆ·æ¶ˆæ¯: {state['current_message']}

è¯·åˆ¤æ–­ï¼š
1. æ„å›¾ç±»å‹ï¼ˆinformation_sharing/question_asking/clarification/greeting/otherï¼‰
2. å½“å‰å¯¹è¯é˜¶æ®µï¼ˆinitial/exploring/deepening/concludingï¼‰

è¿”å›JSONæ ¼å¼ï¼š
{{
    "intent": "...",
    "stage": "..."
}}
"""
        
        response = self.llm.invoke([SystemMessage(content=prompt)])
        try:
            result = json.loads(response.content)
        except json.JSONDecodeError as e:
            logger.error(f"æ„å›¾è¯†åˆ«å“åº”è§£æå¤±è´¥: {e}")
            logger.error(f"åŸå§‹å“åº”: {response.content}")
            raise ValueError(f"æ„å›¾è¯†åˆ«å“åº”æ ¼å¼é”™è¯¯: {str(e)}")
        
        intent = result.get("intent", "other")
        conversation_stage = result.get("stage", "exploring")
        
        # åŸºäºæ„å›¾è®¾ç½®æ˜¯å¦éœ€è¦æå–çŸ¥è¯†
        should_extract = False
        if intent == "information_sharing":
            should_extract = True
        elif intent == "greeting":
            should_extract = False
        elif intent == "question_asking":
            # é—®é¢˜å¯èƒ½åŒ…å«çŸ¥è¯†ï¼Œä¹Ÿå¯èƒ½ä¸åŒ…å«
            # è¿™é‡Œç®€å•å¤„ç†ï¼Œå¦‚æœæ˜¯æ¢ç´¢é˜¶æ®µçš„é—®é¢˜ï¼Œå¯èƒ½æœ‰çŸ¥è¯†
            should_extract = conversation_stage in ["exploring", "deepening"]
        elif intent == "other":
            # å¯¹äº other ç±»å‹ï¼ŒåŸºäºæ–‡æœ¬é•¿åº¦å’Œå†…å®¹å¯†åº¦åˆ¤æ–­
            # é•¿æ–‡æœ¬ï¼ˆè¶…è¿‡100å­—ç¬¦ï¼‰æˆ–åŒ…å«ä¸“ä¸šæœ¯è¯­çš„æ–‡æœ¬åº”è¯¥æå–
            text_length = len(state['current_message'])
            if text_length > 100:
                should_extract = True
                logger.debug(f"é•¿æ–‡æœ¬({text_length}å­—ç¬¦)è¢«è¯†åˆ«ä¸ºéœ€è¦æå–çŸ¥è¯†")
            else:
                should_extract = False
        else:
            should_extract = False
        
        # æ„å›¾å­˜å‚¨åœ¨ step_results ä¸­ï¼Œä¸æ±¡æŸ“é¡¶çº§ state
        step_results = state.get('step_results', {}).copy()
        step_results["intent_recognition"] = {
            "intent": intent,
            "should_extract": should_extract,
            "stage": conversation_stage
        }
        
        # èŠ‚ç‚¹å®Œæˆäº‹ä»¶
        events.append({
            "type": "node_complete",
            "node": "intent_recognition",
            "message": f"âœ… æ„å›¾è¯†åˆ«å®Œæˆ: {intent}",
            "result": {
                "intent": intent,
                "stage": conversation_stage,
                "should_extract": should_extract
            },
            "timestamp": datetime.now().isoformat()
        })
        
        completed_steps = ["intent_recognition"]
        thinking_process.append(f"è¯†åˆ«åˆ°æ„å›¾: {intent}, å¯¹è¯é˜¶æ®µ: {conversation_stage}")
        
        # è¿”å›æ›´æ–°çš„å­—æ®µ
        return {
            "current_step": current_step,
            "conversation_stage": conversation_stage,
            "should_extract": should_extract,
            "step_results": step_results,
            "completed_steps": completed_steps,
            "thinking_process": thinking_process,
            "events": events
        }
    
    def _route_after_intent(self, state: TrainingState) -> str:
        if state.get('should_extract', False):
            return "extract"
        elif state.get('total_knowledge_points', 0) > 5:
            return "analyze"
        else:
            return "direct"
    
    async def _extract_knowledge(self, state: TrainingState) -> Dict[str, Any]:
        events = [{
            "type": "node_start",
            "node": "knowledge_extraction",
            "message": "ğŸ§  å¼€å§‹æå–çŸ¥è¯†ç‚¹...",
            "timestamp": datetime.now().isoformat()
        }]
        
        current_step = "extracting_knowledge"
        thinking_process = ["æ­£åœ¨æå–çŸ¥è¯†ç‚¹..."]
        
        if not state.get('should_extract', False):
            extracted_knowledge = {"entities": [], "relationships": []}
            completed_steps = ["knowledge_extraction"]
            
            events.append({
                "type": "node_complete",
                "node": "knowledge_extraction",
                "message": "â„¹ï¸ æ— éœ€æå–çŸ¥è¯†",
                "timestamp": datetime.now().isoformat()
            })
            
            return {
                "current_step": current_step,
                "extracted_knowledge": extracted_knowledge,
                "completed_steps": completed_steps,
                "thinking_process": thinking_process,
                "events": events
            }
        
        extraction_result = await self.knowledge_extractor.extract(state['current_message'])
        extracted_knowledge = extraction_result
        
        entity_count = len(extraction_result.get("entities", []))
        relationship_count = len(extraction_result.get("relationships", []))
        
        for entity in extraction_result.get("entities", []):
            await self.graph_service.store_digital_human_entity(state['digital_human_id'], entity)
        
        for relationship in extraction_result.get("relationships", []):
            await self.graph_service.store_digital_human_relationship(state['digital_human_id'], relationship)
        
        step_results = state.get('step_results', {}).copy()
        step_results["knowledge_extraction"] = {
            "entities_count": entity_count,
            "relationships_count": relationship_count,
            "extracted": extraction_result
        }
        
        events.append({
            "type": "node_complete",
            "node": "knowledge_extraction",
            "message": f"âœ… çŸ¥è¯†æå–å®Œæˆ: {entity_count} ä¸ªå®ä½“, {relationship_count} ä¸ªå…³ç³»",
            "result": {
                "entities_count": entity_count,
                "relationships_count": relationship_count
            },
            "timestamp": datetime.now().isoformat()
        })
        
        completed_steps = ["knowledge_extraction"]
        thinking_process.append(f"æå–åˆ° {entity_count} ä¸ªå®ä½“, {relationship_count} ä¸ªå…³ç³»")
        
        return {
            "current_step": current_step,
            "extracted_knowledge": extracted_knowledge,
            "step_results": step_results,
            "completed_steps": completed_steps,
            "thinking_process": thinking_process,
            "events": events
        }
    
    def _analyze_context(self, state: TrainingState) -> Dict[str, Any]:
        events = [{
            "type": "node_start",
            "node": "context_analysis",
            "message": "ğŸ” å¼€å§‹åˆ†æçŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡...",
            "timestamp": datetime.now().isoformat()
        }]
        
        current_step = "analyzing_context"
        thinking_process = ["æ­£åœ¨åˆ†æçŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡..."]
        
        context = self._get_current_context(state['digital_human_id'])
        knowledge_context = context
        total_knowledge_points = context.get("total_knowledge_points", 0)
        categories = context.get("categories", {})
        
        should_explore_deeper = False
        if total_knowledge_points > 20 and not categories.get("hobby"):
            should_explore_deeper = True
        elif total_knowledge_points > 10 and len(categories) < 3:
            should_explore_deeper = True
        
        step_results = state.get('step_results', {}).copy()
        step_results["context_analysis"] = {
            "total_points": total_knowledge_points,
            "categories_count": len(categories),
            "should_explore_deeper": should_explore_deeper
        }
        
        events.append({
            "type": "node_complete",
            "node": "context_analysis",
            "message": f"âœ… ä¸Šä¸‹æ–‡åˆ†æå®Œæˆ: {total_knowledge_points} ä¸ªçŸ¥è¯†ç‚¹",
            "result": {
                "total_points": total_knowledge_points,
                "categories_count": len(categories)
            },
            "timestamp": datetime.now().isoformat()
        })
        
        completed_steps = ["context_analysis"]
        thinking_process.append(f"å·²äº†è§£ {total_knowledge_points} ä¸ªçŸ¥è¯†ç‚¹ï¼Œæ¶µç›– {len(categories)} ä¸ªé¢†åŸŸ")
        
        return {
            "current_step": current_step,
            "knowledge_context": knowledge_context,
            "total_knowledge_points": total_knowledge_points,
            "categories": categories,
            "should_explore_deeper": should_explore_deeper,
            "step_results": step_results,
            "completed_steps": completed_steps,
            "thinking_process": thinking_process,
            "events": events
        }
    
    def _generate_question(self, state: TrainingState) -> Dict[str, Any]:
        events = [{
            "type": "node_start",
            "node": "question_generation",
            "message": "â“ å¼€å§‹ç”Ÿæˆå¼•å¯¼æ€§é—®é¢˜...",
            "timestamp": datetime.now().isoformat()
        }]
        
        current_step = "generating_question"
        thinking_process = ["æ­£åœ¨ç”Ÿæˆå¼•å¯¼æ€§é—®é¢˜..."]
        
        context_prompt = self._build_context_prompt(state)
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ­£åœ¨äº†è§£ç”¨æˆ·çš„æ•°å­—äººã€‚åŸºäºå½“å‰å¯¹è¯çŠ¶æ€ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ªå¼•å¯¼æ€§é—®é¢˜ã€‚

{context_prompt}

è¦æ±‚ï¼š
1. é—®é¢˜è¦è‡ªç„¶ã€å‹å¥½
2. æ ¹æ®ç”¨æˆ·åˆšæ‰çš„å›ç­”å»¶ä¼¸
3. é€æ­¥æ·±å…¥äº†è§£ç”¨æˆ·
4. ä¸è¦é‡å¤å·²ç»é—®è¿‡çš„å†…å®¹

ç”Ÿæˆä¸€ä¸ªå¼•å¯¼æ€§é—®é¢˜ï¼š
"""
        
        response = self.llm.invoke([SystemMessage(content=prompt)])
        next_question = response.content.strip()
        
        step_results = state.get('step_results', {}).copy()
        step_results["question_generation"] = {
            "question": next_question,
            "based_on_stage": state.get('conversation_stage', 'exploring')
        }
        
        events.append({
            "type": "node_complete",
            "node": "question_generation",
            "message": "âœ… é—®é¢˜ç”Ÿæˆå®Œæˆ",
            "result": {
                "question": next_question[:50] + "..." if len(next_question) > 50 else next_question
            },
            "timestamp": datetime.now().isoformat()
        })
        
        completed_steps = ["question_generation"]
        thinking_process.append("å·²ç”Ÿæˆå¼•å¯¼æ€§é—®é¢˜")
        
        return {
            "current_step": current_step,
            "next_question": next_question,
            "step_results": step_results,
            "completed_steps": completed_steps,
            "thinking_process": thinking_process,
            "events": events
        }
    
    def _build_context_prompt(self, state: Dict[str, Any]) -> str:
        prompt_parts = []
        
        if state.get('current_message'):
            prompt_parts.append(f"ç”¨æˆ·åˆšæ‰è¯´: {state['current_message']}")
        
        extracted_knowledge = state.get('extracted_knowledge', {})
        if extracted_knowledge and extracted_knowledge.get("entities"):
            entities = extracted_knowledge["entities"]
            entity_names = [e.get("name") for e in entities[:3]]
            prompt_parts.append(f"æå–åˆ°çš„å®ä½“: {', '.join(entity_names)}")
        
        total_knowledge_points = state.get('total_knowledge_points', 0)
        if total_knowledge_points > 0:
            prompt_parts.append(f"å·²äº†è§£çš„çŸ¥è¯†ç‚¹æ•°: {total_knowledge_points}")
        
        categories = state.get('categories', {})
        if categories:
            cat_summary = []
            for cat, info in categories.items():
                if isinstance(info, dict) and info.get("count"):
                    cat_summary.append(f"{cat}({info['count']}ä¸ª)")
            if cat_summary:
                prompt_parts.append(f"å·²äº†è§£çš„é¢†åŸŸ: {', '.join(cat_summary)}")
        
        conversation_stage = state.get('conversation_stage', 'exploring')
        prompt_parts.append(f"å½“å‰å¯¹è¯é˜¶æ®µ: {conversation_stage}")
        
        return "\n".join(prompt_parts)
    
    async def _save_message(self, state: TrainingState) -> Dict[str, Any]:
        events = [{
            "type": "node_start",
            "node": "save_message",
            "message": "ğŸ’¾ å¼€å§‹ä¿å­˜å¯¹è¯è®°å½•...",
            "timestamp": datetime.now().isoformat()
        }]
        
        current_step = "saving_message"
        thinking_process = ["æ­£åœ¨ä¿å­˜å¯¹è¯è®°å½•..."]
        
        message_data = {
            "digital_human_id": state['digital_human_id'],
            "user_id": state['user_id'],
            "content": state['current_message'],
            "extracted_knowledge": state.get('extracted_knowledge', {}),
            "conversation_stage": state.get('conversation_stage', 'exploring'),
            "next_question": state.get('next_question', '')
        }
        
        step_results = state.get('step_results', {}).copy()
        step_results["message_saving"] = {
            "saved": True,
            "message_length": len(state['current_message'])
        }
        
        events.append({
            "type": "node_complete",
            "node": "save_message",
            "message": "âœ… å¯¹è¯è®°å½•ä¿å­˜å®Œæˆ",
            "timestamp": datetime.now().isoformat()
        })
        
        completed_steps = ["save_message"]
        thinking_process.append("å¯¹è¯è®°å½•å·²ä¿å­˜")
        
        return {
            "current_step": current_step,
            "step_results": step_results,
            "completed_steps": completed_steps,
            "thinking_process": thinking_process,
            "events": events
        }
    
    def _get_current_context(self, digital_human_id: int) -> Dict[str, Any]:
        try:
            return self.graph_service.get_digital_human_knowledge_context(digital_human_id)
        except Exception as e:
            logger.error(f"è·å–è®­ç»ƒä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")
            return {"total_knowledge_points": 0, "categories": {}, "recent_entities": []}
    
    async def _save_and_send_assistant_message(
        self,
        digital_human_id: int,
        user_id: int,
        question: str
    ) -> AsyncGenerator[str, None]:
        """ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯å¹¶å‘é€äº‹ä»¶"""
        assistant_msg = DigitalHumanTrainingMessage(
            digital_human_id=digital_human_id,
            user_id=user_id,
            role="assistant",
            content=question
        )
        self.db.add(assistant_msg)
        self.db.flush()
        
        yield json.dumps({
            "type": "assistant_question",
            "id": assistant_msg.id,
            "data": question
        }, ensure_ascii=False)
    
    def _extract_next_question(self, result) -> Optional[str]:
        """ä»ç»“æœä¸­æå–ä¸‹ä¸€ä¸ªé—®é¢˜"""
        if not result:
            return None
            
        # å°è¯•ä½œä¸ºå­—å…¸è®¿é—®
        if hasattr(result, '__getitem__') and 'next_question' in result:
            return result['next_question']
        # å°è¯•ä½œä¸ºå¯¹è±¡å±æ€§è®¿é—®
        elif hasattr(result, 'next_question'):
            return result.next_question
            
        return None
    
    async def process_training_conversation(
        self,
        digital_human_id: int,
        user_message: str,
        user_id: int
    ) -> Generator[str, None, None]:
        user_msg = None
        state = None
        
        try:
            user_msg = DigitalHumanTrainingMessage(
                digital_human_id=digital_human_id,
                user_id=user_id,
                role="user",
                content=user_message
            )
            self.db.add(user_msg)
            self.db.flush()
            
            yield json.dumps({
                "type": "user_message",
                "id": user_msg.id,
                "data": user_message
            }, ensure_ascii=False)
            
            state = TrainingState(
                digital_human_id=digital_human_id,
                user_id=user_id,
                current_message=user_message,
                messages=[HumanMessage(content=user_message)]
            )
            
            yield json.dumps({
                "type": "thinking",
                "data": "å¼€å§‹åˆ†æå¯¹è¯..."
            }, ensure_ascii=False)
            
            # ä¿å­˜æœ€ç»ˆçŠ¶æ€
            final_state = None
            previous_state = None
            
            # ä½¿ç”¨ astream è·å–çŠ¶æ€æ›´æ–°
            async for chunk in self.training_graph.astream(state):
                # chunk æ˜¯ {"èŠ‚ç‚¹å": èŠ‚ç‚¹çŠ¶æ€} æ ¼å¼
                if chunk and isinstance(chunk, dict):
                    logger.debug(f"ğŸ“Š çŠ¶æ€æ›´æ–°: {list(chunk.keys())}")
                    
                    # å¤„ç†æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å‡º
                    for node_name, node_state in chunk.items():
                        # è·³è¿‡å†…éƒ¨èŠ‚ç‚¹
                        if node_name.startswith('__'):
                            continue
                            
                        # èŠ‚ç‚¹çŠ¶æ€å¯èƒ½æ˜¯ dict æˆ–å¯¹è±¡
                        if isinstance(node_state, dict):
                            # ä» dict ä¸­æå–å­—æ®µ
                            events = node_state.get('events', [])
                            completed_steps = node_state.get('completed_steps', [])
                            thinking_process = node_state.get('thinking_process', [])
                            extracted_knowledge = node_state.get('extracted_knowledge', {})
                            next_question = node_state.get('next_question', '')
                            conversation_stage = node_state.get('conversation_stage', '')
                        else:
                            # ä»å¯¹è±¡ä¸­æå–å­—æ®µ
                            events = getattr(node_state, 'events', [])
                            completed_steps = getattr(node_state, 'completed_steps', [])
                            thinking_process = getattr(node_state, 'thinking_process', [])
                            extracted_knowledge = getattr(node_state, 'extracted_knowledge', {})
                            next_question = getattr(node_state, 'next_question', '')
                            conversation_stage = getattr(node_state, 'conversation_stage', '')
                            
                        # å‘é€èŠ‚ç‚¹äº‹ä»¶
                        if events:
                            for event in events:
                                # å‘é€èŠ‚ç‚¹å†…éƒ¨çš„äº‹ä»¶
                                logger.debug(f"ğŸ“¨ å‘é€äº‹ä»¶: {event.get('type')} - {event.get('node')}")
                                yield json.dumps(event, ensure_ascii=False)
                        
                        # æ£€æµ‹æ–°å®Œæˆçš„æ­¥éª¤
                        if completed_steps:
                            if previous_state:
                                prev_completed = previous_state.get('completed_steps', []) if isinstance(previous_state, dict) else getattr(previous_state, 'completed_steps', [])
                                # æ‰¾å‡ºæ–°å®Œæˆçš„æ­¥éª¤
                                new_steps = set(completed_steps) - set(prev_completed)
                                for step in new_steps:
                                    # å¦‚æœäº‹ä»¶ä¸­æ²¡æœ‰åŒ…å«ï¼Œæ‰å‘é€
                                    if not any(e.get('type') == 'node_complete' and e.get('node') == step for e in events):
                                        yield json.dumps({
                                            "type": "node_complete",
                                            "node": step,
                                            "data": f"âœ… å®Œæˆ: {step}",
                                            "timestamp": datetime.now().isoformat()
                                        }, ensure_ascii=False)
                            
                        # æ£€æŸ¥æ€è€ƒè¿‡ç¨‹
                        if thinking_process:
                            # å‘é€æ–°çš„æ€è€ƒè¿‡ç¨‹
                            if previous_state:
                                prev_thinking = previous_state.get('thinking_process', []) if isinstance(previous_state, dict) else getattr(previous_state, 'thinking_process', [])
                                prev_count = len(prev_thinking)
                                new_thoughts = thinking_process[prev_count:]
                                for thought in new_thoughts:
                                    yield json.dumps({
                                        "type": "thinking",
                                        "data": thought
                                    }, ensure_ascii=False)
                            else:
                                for thought in thinking_process:
                                    yield json.dumps({
                                        "type": "thinking",
                                        "data": thought
                                    }, ensure_ascii=False)
                        
                        # æ£€æŸ¥çŸ¥è¯†æå–
                        if extracted_knowledge and extracted_knowledge.get('entities'):
                            user_msg.extracted_knowledge = extracted_knowledge
                            user_msg.extraction_metadata = {
                                "extraction_time": datetime.now().isoformat(),
                                "stage": conversation_stage
                            }
                            yield json.dumps({
                                "type": "knowledge_extracted",
                                "id": user_msg.id,
                                "data": extracted_knowledge['entities']
                            }, ensure_ascii=False)
                        
                        # æ£€æŸ¥ä¸‹ä¸€ä¸ªé—®é¢˜
                        if next_question:
                            final_state = node_state
                            logger.info(f"âœ¨ æ‰¾åˆ°ä¸‹ä¸€ä¸ªé—®é¢˜: {next_question[:50]}...")
                        
                        # ä¿å­˜å½“å‰çŠ¶æ€
                        previous_state = node_state
                    
            
            # åœ¨æµç»“æŸåï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆçŠ¶æ€
            if final_state:
                next_q = final_state.get('next_question') if isinstance(final_state, dict) else getattr(final_state, 'next_question', None)
                if next_q:
                    logger.info(f"ğŸ¤– ä»æœ€ç»ˆçŠ¶æ€æå–é—®é¢˜: {next_q}")
                    async for msg in self._save_and_send_assistant_message(
                        digital_human_id, user_id, next_q
                    ):
                        yield msg
            else:
                # å¦‚æœæ²¡æœ‰ä»æµä¸­è·å–åˆ°çŠ¶æ€ï¼Œå°è¯•ç›´æ¥è¿è¡Œ
                logger.debug("æ²¡æœ‰ä»æµäº‹ä»¶ä¸­è·å–åˆ°æœ€ç»ˆçŠ¶æ€ï¼Œå°è¯•ç›´æ¥è¿è¡Œ...")
                result = await self.training_graph.ainvoke(state)
                next_question = self._extract_next_question(result)
                
                if next_question:
                    logger.info(f"ğŸ¤– ä»ç›´æ¥è¿è¡Œç»“æœæå–é—®é¢˜: {next_question}")
                    async for msg in self._save_and_send_assistant_message(
                        digital_human_id, user_id, next_question
                    ):
                        yield msg
            
            self.db.commit()
        except Exception as e:
            logger.error(f"è®­ç»ƒå¯¹è¯å¤„ç†å¤±è´¥: {str(e)}")
            yield json.dumps({
                "type": "error",
                "data": f"å¤„ç†å¤±è´¥: {str(e)}"
            }, ensure_ascii=False)
    
    
    
    
