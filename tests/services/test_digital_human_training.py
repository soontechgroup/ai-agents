import pytest
import asyncio
import json
from unittest.mock import Mock, AsyncMock, MagicMock, patch
from typing import List, Dict, Any
from datetime import datetime

from app.services.digital_human_training_service import (
    DigitalHumanTrainingService,
    TrainingState
)
from app.core.models import DigitalHumanTrainingMessage
from langchain.schema import HumanMessage, SystemMessage


class TestDigitalHumanTrainingService:
    
    @pytest.fixture
    def mock_training_message_repo(self):
        repo = Mock()
        message_counter = [0]
        
        def create_training_message_side_effect(**kwargs):
            message_counter[0] += 1
            msg = DigitalHumanTrainingMessage(
                id=message_counter[0],
                digital_human_id=kwargs.get('digital_human_id'),
                user_id=kwargs.get('user_id'),
                role=kwargs.get('role'),
                content=kwargs.get('content'),
                extracted_knowledge=kwargs.get('extracted_knowledge'),
                extraction_metadata=kwargs.get('extraction_metadata')
            )
            return msg
        
        repo.create_training_message = Mock(side_effect=create_training_message_side_effect)
        repo.commit = Mock()
        repo.rollback = Mock()
        return repo
    
    @pytest.fixture
    def mock_knowledge_extractor(self):
        extractor = AsyncMock()
        extractor.extract = AsyncMock(return_value={
            "entities": [
                {"name": "æµ‹è¯•å®ä½“", "type": "person", "confidence": 0.9},
                {"name": "æµ‹è¯•å…¬å¸", "type": "organization", "confidence": 0.85}
            ],
            "relationships": [
                {
                    "source": "æµ‹è¯•å®ä½“",
                    "target": "æµ‹è¯•å…¬å¸",
                    "relation_type": "å·¥ä½œäº",
                    "confidence": 0.8
                }
            ]
        })
        return extractor
    
    @pytest.fixture
    def mock_graph_service(self):
        service = Mock()
        # ä¸ºæ–°å¢çš„æ–¹æ³•åˆ›å»ºå¼‚æ­¥ mock
        service.store_digital_human_entity = AsyncMock(return_value=True)
        service.store_digital_human_relationship = AsyncMock(return_value=True)
        service.get_digital_human_knowledge_context = Mock(return_value={
            "total_knowledge_points": 5,
            "categories": {
                "profession": {"count": 2, "examples": ["å·¥ç¨‹å¸ˆ", "å¼€å‘è€…"]},
                "skill": {"count": 2, "examples": ["Python", "JavaScript"]},
                "project": {"count": 1, "examples": ["é¡¹ç›®A"]}
            },
            "recent_entities": []
        })
        return service
    
    @pytest.fixture
    def mock_graph_repo(self):
        repo = Mock()
        repo.execute_query = Mock(return_value=[
            ("profession", ["å·¥ç¨‹å¸ˆ", "å¼€å‘è€…"], 2),
            ("skill", ["Python", "JavaScript"], 2),
            ("project", ["é¡¹ç›®A"], 1)
        ])
        return repo
    
    @pytest.fixture
    async def training_service(self, mock_training_message_repo, mock_knowledge_extractor, mock_graph_service):
        service = DigitalHumanTrainingService(
            training_message_repo=mock_training_message_repo,
            knowledge_extractor=mock_knowledge_extractor,
            graph_service=mock_graph_service
        )
        
        # ä¸å†è®¾ç½® graph_repoï¼Œå› ä¸ºå·²ç»ä»æœåŠ¡ä¸­ç§»é™¤äº†
        # ä¸å†æ›¿æ¢ llm å’Œ training_graphï¼Œä½¿ç”¨ service è‡ªå¸¦çš„çœŸå®ç»„ä»¶
        # service.llm å·²ç»åœ¨ __init__ ä¸­åˆå§‹åŒ–ä¸ºçœŸå®çš„ ChatOpenAI
        # service.training_graph å·²ç»åœ¨ __init__ ä¸­æ„å»ºä¸ºçœŸå®çš„ LangGraph
        
        return service
    
    @pytest.mark.asyncio
    async def test_intent_recognition_node(self, training_service):
        print("\n========== æµ‹è¯•æ„å›¾è¯†åˆ«èŠ‚ç‚¹ ==========")
        state = {
            "digital_human_id": 1,
            "user_id": 1,
            "current_message": "æˆ‘æ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆï¼Œåœ¨é˜¿é‡Œå·´å·´å·¥ä½œäº†5å¹´",
            "messages": [],
            "extracted_knowledge": {},
            "knowledge_context": {},
            "next_question": "",
            "should_extract": False,
            "should_explore_deeper": False,
            "conversation_stage": "initial",
            "total_knowledge_points": 0,
            "categories": {},
            "current_step": "",
            "completed_steps": [],
            "step_results": {},
            "thinking_process": [],
            "events": []
        }
        print(f"è¾“å…¥æ¶ˆæ¯: {state['current_message']}")
        
        result_state = training_service._recognize_intent(state)
        
        print(f"å½“å‰æ­¥éª¤: {result_state.get('current_step')}")
        print(f"å·²å®Œæˆæ­¥éª¤: {result_state.get('completed_steps')}")
        intent = result_state.get('step_results', {}).get('intent_recognition', {}).get('intent', 'æœªçŸ¥')
        print(f"è¯†åˆ«åˆ°çš„æ„å›¾: {intent}")
        print(f"æ˜¯å¦éœ€è¦æŠ½å–çŸ¥è¯†: {result_state.get('should_extract')}")
        print(f"å¯¹è¯é˜¶æ®µ: {result_state.get('conversation_stage')}")
        print(f"æ€è€ƒè¿‡ç¨‹: {result_state.get('thinking_process')}")
        print(f"æ­¥éª¤ç»“æœ: {result_state.get('step_results')}")
        print(f"äº‹ä»¶æ•°é‡: {len(result_state.get('events', []))}")
        print("=====================================\n")
        
        assert result_state.get('current_step') == "recognizing_intent"
        assert "intent_recognition" in result_state.get('completed_steps', [])
        # æ£€æŸ¥æ„å›¾å­˜å‚¨åœ¨ step_results ä¸­
        assert "intent_recognition" in result_state.get('step_results', {})
        assert "intent" in result_state.get('step_results', {}).get("intent_recognition", {})
        # çœŸå® AI å¯èƒ½æœ‰ä¸åŒçš„åˆ¤æ–­ï¼Œæ‰€ä»¥åªéªŒè¯å­—æ®µå­˜åœ¨
        assert isinstance(result_state.get('should_extract'), bool)
        assert len(result_state.get('thinking_process', [])) >= 2
        print(f"âœ… çœŸå® AI åˆ¤æ–­: intent = {intent}, should_extract = {result_state.get('should_extract')}")
    
    @pytest.mark.asyncio
    async def test_intent_recognition_json_error(self, training_service):
        """æµ‹è¯•æ„å›¾è¯†åˆ«JSONè§£æå¤±è´¥æ—¶åº”è¯¥æŠ›å‡ºå¼‚å¸¸"""
        state = TrainingState(
            digital_human_id=1,
            user_id=1,
            current_message="æµ‹è¯•æ¶ˆæ¯"
        )
        
        # ä¸´æ—¶æ¨¡æ‹Ÿä¸€ä¸ªåçš„å“åº”æ¥æµ‹è¯•é”™è¯¯å¤„ç†
        # è¿™æ˜¯å”¯ä¸€éœ€è¦ mock çš„åœ°æ–¹ï¼Œå› ä¸ºæˆ‘ä»¬è¦æµ‹è¯•é”™è¯¯å¤„ç†
        bad_response = Mock()
        bad_response.content = "è¿™ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSON"
        original_llm = training_service.llm
        training_service.llm = Mock()
        training_service.llm.invoke = Mock(return_value=bad_response)
        
        # åº”è¯¥æŠ›å‡º ValueError
        with pytest.raises(ValueError, match="æ„å›¾è¯†åˆ«å“åº”æ ¼å¼é”™è¯¯"):
            training_service._recognize_intent(state)
        
        # æ¢å¤åŸæ¥çš„ llm
        training_service.llm = original_llm
    
    @pytest.mark.asyncio
    async def test_knowledge_extraction_node(self, training_service):
        state = TrainingState(
            digital_human_id=1,
            user_id=1,
            current_message="æˆ‘åœ¨é˜¿é‡Œå·´å·´å·¥ä½œ",
            should_extract=True
        )
        
        result_state = await training_service._extract_knowledge(state)
        
        assert result_state.get('current_step') == "extracting_knowledge"
        assert "knowledge_extraction" in result_state.get('completed_steps', [])
        assert len(result_state.get('extracted_knowledge', {}).get("entities", [])) > 0
        assert "knowledge_extraction" in result_state.get('step_results', {})
    
    @pytest.mark.asyncio
    async def test_question_generation_node(self, training_service):
        state = TrainingState(
            digital_human_id=1,
            user_id=1,
            current_message="æˆ‘æ˜¯å·¥ç¨‹å¸ˆ",
            conversation_stage="exploring"
        )
        
        result_state = training_service._generate_question(state)
        
        assert result_state.get('current_step') == "generating_question"
        assert "question_generation" in result_state.get('completed_steps', [])
        assert result_state.get('next_question') != ""
        assert "question_generation" in result_state.get('step_results', {})
    
    @pytest.mark.asyncio
    async def test_streaming_events_collection(self, training_service):
        print("\n========== æµ‹è¯•æµå¼äº‹ä»¶æ”¶é›† ==========")
        events = []
        node_events = {"starts": [], "completes": []}
        
        print("å¼€å§‹å¤„ç†å¯¹è¯ï¼Œæ”¶é›†æµå¼äº‹ä»¶...")
        async for event in training_service.process_training_conversation(
            digital_human_id=1,
            user_message="æˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…ï¼Œå¸®æˆ‘å†™ä¸€ä¸ªå†’æ³¡å‡½æ•°",
            user_id=1
        ):
            event_obj = json.loads(event)
            events.append(event_obj)
            
            # è®°å½•èŠ‚ç‚¹äº‹ä»¶
            if event_obj.get('type') == 'node_start':
                node_events["starts"].append(event_obj.get('node'))
                print(f"ğŸ”µ [{event_obj.get('type')}] èŠ‚ç‚¹: {event_obj.get('node')}")
            elif event_obj.get('type') == 'node_complete':
                node_events["completes"].append(event_obj.get('node'))
                print(f"ğŸŸ¢ [{event_obj.get('type')}] èŠ‚ç‚¹: {event_obj.get('node')}")
            elif event_obj.get('type') == 'thinking':
                print(f"ğŸ’­ [{event_obj.get('type')}] {event_obj.get('data', '')[:50]}...")
            else:
                data_str = str(event_obj.get('data', ''))[:100] if event_obj.get('data') else ''
                print(f"ğŸ“ [{event_obj.get('type')}]: {data_str}")
        
        print(f"\næ€»å…±æ”¶é›†åˆ° {len(events)} ä¸ªäº‹ä»¶")
        event_types = [e["type"] for e in events]
        print(f"äº‹ä»¶ç±»å‹åˆ—è¡¨: {event_types}")
        print(f"èŠ‚ç‚¹å¼€å§‹äº‹ä»¶: {node_events['starts']}")
        print(f"èŠ‚ç‚¹å®Œæˆäº‹ä»¶: {node_events['completes']}")
        
        # éªŒè¯åŸºæœ¬äº‹ä»¶
        assert "user_message" in event_types
        assert any(t in event_types for t in ["thinking", "node_start", "node_complete"])
        
        # éªŒè¯èŠ‚ç‚¹äº‹ä»¶
        if node_events["starts"]:
            print(f"âœ… æ£€æµ‹åˆ° {len(node_events['starts'])} ä¸ªèŠ‚ç‚¹å¼€å§‹äº‹ä»¶")
            assert "intent_recognition" in ' '.join(node_events["starts"])
        
        if node_events["completes"]:
            print(f"âœ… æ£€æµ‹åˆ° {len(node_events['completes'])} ä¸ªèŠ‚ç‚¹å®Œæˆäº‹ä»¶")
            assert "intent_recognition" in ' '.join(node_events["completes"])
        
        user_msg_event = next(e for e in events if e["type"] == "user_message")
        assert "id" in user_msg_event
        print("=====================================\n")
    
    @pytest.mark.asyncio
    async def test_workflow_routing_logic(self, training_service):
        state1 = TrainingState(
            digital_human_id=1,
            user_id=1,
            should_extract=True,
            total_knowledge_points=0
        )
        assert training_service._route_after_intent(state1) == "extract"
        
        state2 = TrainingState(
            digital_human_id=1,
            user_id=1,
            should_extract=False,
            total_knowledge_points=10
        )
        assert training_service._route_after_intent(state2) == "analyze"
        
        state3 = TrainingState(
            digital_human_id=1,
            user_id=1,
            should_extract=False,
            total_knowledge_points=3
        )
        assert training_service._route_after_intent(state3) == "direct"
    
    @pytest.mark.asyncio
    async def test_fallback_to_ainvoke(self, training_service):
        """æµ‹è¯•å½“ astream ä¸å¯ç”¨æ—¶çš„å¼‚å¸¸å¤„ç†"""
        with patch.object(training_service.training_graph, 'astream', side_effect=AttributeError("'async_generator' object has no attribute 'astream'")):
            events = []
            
            async for event in training_service.process_training_conversation(
                digital_human_id=1,
                user_message="æµ‹è¯•å¼‚å¸¸å¤„ç†",
                user_id=1
            ):
                events.append(json.loads(event))
            
            # éªŒè¯å¼‚å¸¸è¢«æ­£ç¡®æ•è·å¹¶è¿”å›é”™è¯¯äº‹ä»¶
            assert len(events) > 0
            # ç¡®ä¿æœ‰é”™è¯¯äº‹ä»¶äº§ç”Ÿ
            assert any(e["type"] == "error" for e in events)
    
    @pytest.mark.asyncio
    async def test_error_handling(self, training_service):
        training_service.training_message_repo.create_training_message.side_effect = Exception("æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        events = []
        async for event in training_service.process_training_conversation(
            digital_human_id=1,
            user_message="æµ‹è¯•é”™è¯¯",
            user_id=1
        ):
            events.append(json.loads(event))
        
        assert any(e["type"] == "error" for e in events)
        error_event = next(e for e in events if e["type"] == "error")
        assert "å¤±è´¥" in error_event["data"]
    
    @pytest.mark.asyncio
    async def test_message_persistence(self, training_service):
        events = []
        
        async for event in training_service.process_training_conversation(
            digital_human_id=1,
            user_message="æµ‹è¯•æ¶ˆæ¯æŒä¹…åŒ–",
            user_id=1
        ):
            events.append(json.loads(event))
        
        # éªŒè¯ training_message_repo çš„ create_training_message è¢«è°ƒç”¨
        assert training_service.training_message_repo.create_training_message.called
        
        # è·å–è°ƒç”¨å‚æ•°
        save_calls = training_service.training_message_repo.create_training_message.call_args_list
        
        # éªŒè¯è‡³å°‘æœ‰ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯è¢«ä¿å­˜
        user_message_calls = [call for call in save_calls if call.kwargs.get('role') == 'user']
        assert len(user_message_calls) > 0
        assert user_message_calls[0].kwargs['content'] == "æµ‹è¯•æ¶ˆæ¯æŒä¹…åŒ–"
        
        # éªŒè¯ commit è¢«è°ƒç”¨
        assert training_service.training_message_repo.commit.called
    
    @pytest.mark.asyncio
    async def test_complete_workflow_integration(self, training_service):
        print("\n========== æµ‹è¯•å®Œæ•´å·¥ä½œæµé›†æˆ ==========")
        collected_events = []
        
        user_message = """
        ä½ å¥½å•Š
        """
        print(f"ğŸ“ ç”¨æˆ·æ¶ˆæ¯: {user_message[:100]}... (å…±{len(user_message)}å­—ç¬¦)")
        print("\nğŸš€ æ‰§è¡Œå·¥ä½œæµ:")
        
        async for event in training_service.process_training_conversation(
            digital_human_id=1,
            user_message=user_message,
            user_id=1
        ):
            event_obj = json.loads(event)
            collected_events.append(event_obj)
            event_type = event_obj.get('type')
            
            # æ ¹æ®äº‹ä»¶ç±»å‹æ˜¾ç¤ºä¸åŒçš„ä¿¡æ¯
            if event_type == 'thinking':
                # è¿‡æ»¤æ‰thinkingäº‹ä»¶ï¼Œåªè®¡æ•°ä¸æ‰“å°
                continue
            elif event_type == 'user_message':
                # ç”¨æˆ·æ¶ˆæ¯å·²ç»åœ¨å¼€å¤´æ˜¾ç¤ºè¿‡äº†
                continue
            elif event_type == 'node_start':
                # èŠ‚ç‚¹å¼€å§‹ä¸æ˜¾ç¤ºï¼Œåªåœ¨å®Œæˆæ—¶æ˜¾ç¤º
                continue
            elif event_type == 'node_complete':
                node = event_obj.get('node', '')
                result = event_obj.get('result', {})
                
                if node == 'intent_recognition':
                    intent = result.get('intent', 'æœªçŸ¥')
                    stage = result.get('stage', 'æœªçŸ¥')
                    should_extract = result.get('should_extract', False)
                    print(f"  1ï¸âƒ£ æ„å›¾è¯†åˆ« â†’ {intent} (é˜¶æ®µ: {stage}, éœ€è¦æå–: {should_extract})")
                    
                elif node == 'knowledge_extraction':
                    entities_count = result.get('entities_count', 0)
                    relationships_count = result.get('relationships_count', 0)
                    print(f"  2ï¸âƒ£ çŸ¥è¯†æå– â†’ {entities_count}ä¸ªå®ä½“, {relationships_count}ä¸ªå…³ç³»")
                    
                elif node == 'context_analysis':
                    total_points = result.get('total_points', 0)
                    categories_count = result.get('categories_count', 0)
                    print(f"  3ï¸âƒ£ ä¸Šä¸‹æ–‡åˆ†æ â†’ {total_points}ä¸ªçŸ¥è¯†ç‚¹, {categories_count}ä¸ªç±»åˆ«")
                    
                elif node == 'question_generation':
                    question = result.get('question', '')
                    if len(question) > 50:
                        question = question[:50] + '...'
                    print(f"  4ï¸âƒ£ é—®é¢˜ç”Ÿæˆ â†’ \"{question}\"")
                    
                elif node == 'save_message':
                    print(f"  5ï¸âƒ£ æ¶ˆæ¯ä¿å­˜ â†’ å®Œæˆ")
                    
            elif event_type == 'knowledge_extracted':
                entities = event_obj.get('data', [])
                print(f"\n  ğŸ“Š ã€çŸ¥è¯†æå–ç»“æœã€‘")
                print(f"     æå–åˆ° {len(entities)} ä¸ªå®ä½“:")
                for entity in entities:
                    confidence = entity.get('confidence', 'N/A')
                    print(f"       â€¢ {entity.get('name')} - ç±»å‹: {entity.get('type')} (ç½®ä¿¡åº¦: {confidence})")
                print()
                
            elif event_type == 'assistant_question':
                question = event_obj.get('data', '')
                if len(question) > 100:
                    question = question[:100] + '...'
                print(f"\n  ğŸ¤– åŠ©æ‰‹å›å¤: {question}")
            elif event_type == 'error':
                print(f"  âŒ é”™è¯¯: {event_obj.get('data', '')}")
        
        # ç»Ÿè®¡äº‹ä»¶
        thinking_count = len([e for e in collected_events if e.get('type') == 'thinking'])
        actual_events = len(collected_events) - thinking_count
        
        print(f"\nğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
        print(f"  - æ€»äº‹ä»¶æ•°: {len(collected_events)} (è¿‡æ»¤thinkingå: {actual_events})")
        
        # æ£€æŸ¥èŠ‚ç‚¹æ‰§è¡Œæƒ…å†µ
        main_nodes = ['intent_recognition', 'knowledge_extraction', 'context_analysis', 
                      'question_generation', 'save_message']
        successful_nodes = []
        for node in main_nodes:
            node_events = [e for e in collected_events 
                          if e.get('node') == node and e.get('type') == 'node_complete']
            if node_events:
                successful_nodes.append(node)
        
        print(f"  - æ‰§è¡ŒèŠ‚ç‚¹: {len(successful_nodes)}/{len(main_nodes)}")
        if len(successful_nodes) == len(main_nodes):
            print(f"  - âœ… å…¨éƒ¨èŠ‚ç‚¹æˆåŠŸæ‰§è¡Œ")
        
        # éªŒè¯çŸ¥è¯†æå–
        knowledge_events = [e for e in collected_events 
                           if e.get('type') == 'knowledge_extracted']
        if knowledge_events:
            entities = knowledge_events[0].get('data', [])
            print(f"\nğŸ“¢ çŸ¥è¯†æå–éªŒè¯:")
            print(f"  - å®é™…æå–å®ä½“æ•°: {len(entities)}")
            assert len(entities) > 0, "åº”è¯¥æå–åˆ°è‡³å°‘ä¸€ä¸ªå®ä½“"
        
        # åŸºæœ¬éªŒè¯
        event_types = [e["type"] for e in collected_events]
        assert "user_message" in event_types
        assert len(collected_events) >= 3
        
        user_msg_index = event_types.index("user_message")
        assert user_msg_index == 0
        print(f"\nâœ“ ç”¨æˆ·æ¶ˆæ¯æ˜¯ç¬¬ä¸€ä¸ªäº‹ä»¶")
        
        assistant_events = [e for e in collected_events if e["type"] == "assistant_question"]
        if assistant_events:
            assert "id" in assistant_events[0]
            assert assistant_events[0]["data"] != ""
            print(f"âœ“ ç”Ÿæˆäº†åŠ©æ‰‹é—®é¢˜: {assistant_events[0]['data'][:100]}...")
        print("=====================================\n")
    
    @pytest.mark.asyncio
    async def test_no_knowledge_extraction_scenario(self, training_service):
        # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é—®å€™è¯­ï¼ŒçœŸå® AI åº”è¯¥èƒ½è¯†åˆ«è¿™ä¸åŒ…å«çŸ¥è¯†
        state = {
            "digital_human_id": 1,
            "user_id": 1,
            "current_message": "ä½ å¥½",
            "messages": [],
            "extracted_knowledge": {},
            "knowledge_context": {},
            "next_question": "",
            "should_extract": False,
            "should_explore_deeper": False,
            "conversation_stage": "initial",
            "total_knowledge_points": 0,
            "categories": {},
            "current_step": "",
            "completed_steps": [],
            "step_results": {},
            "thinking_process": [],
            "events": []
        }
        
        result_state = training_service._recognize_intent(state)
        # çœŸå® AI åº”è¯¥è¯†åˆ«è¿™æ˜¯ greetingï¼Œä¸éœ€è¦æŠ½å–çŸ¥è¯†
        intent = result_state.get('step_results', {}).get('intent_recognition', {}).get('intent', 'æœªçŸ¥')
        print(f"AI è¯†åˆ«ç»“æœ: intent={intent}, should_extract={result_state.get('should_extract')}")
        
        # å³ä½¿ should_extract æ˜¯ Trueï¼ŒçŸ¥è¯†æŠ½å–ä¹Ÿåº”è¯¥è¿”å›ç©º
        result_state = await training_service._extract_knowledge(result_state)
        # å¯¹äº"ä½ å¥½"è¿™æ ·çš„æ¶ˆæ¯ï¼Œåº”è¯¥æ²¡æœ‰å®ä½“å¯æŠ½å–
        # ä½†ç”±äºæ˜¯ mock çš„ extractorï¼Œå¯èƒ½ä¼šè¿”å›æ¨¡æ‹Ÿæ•°æ®
        print(f"æŠ½å–ç»“æœ: {result_state.get('extracted_knowledge')}")
    
    @pytest.mark.asyncio
    async def test_graph_storage_operations(self, training_service):
        entity = {
            "name": "æµ‹è¯•å®ä½“",
            "type": "person",
            "types": ["person", "professional"],
            "confidence": 0.9,
            "properties": {"role": "engineer"}
        }
        
        # ç°åœ¨åº”è¯¥ä½¿ç”¨ graph_service çš„æ–¹æ³•
        result = await training_service.graph_service.store_digital_human_entity(1, entity)
        assert result is True  # Mock è¿”å› True
        
        relationship = {
            "source": "å®ä½“1",
            "target": "å®ä½“2",
            "relation_type": "å…³ç³»ç±»å‹",
            "confidence": 0.8,
            "properties": {}
        }
        
        result = await training_service.graph_service.store_digital_human_relationship(1, relationship)
        assert result is True  # Mock è¿”å› True
        
        print("âœ… å›¾å­˜å‚¨æ“ä½œå®Œæˆï¼ˆé€šè¿‡ GraphServiceï¼‰")
    
    @pytest.mark.asyncio
    async def test_generate_graph_visualization(self):
        """ç”Ÿæˆå¹¶ä¿å­˜å·¥ä½œæµå›¾çš„å¯è§†åŒ–"""
        print("\n========== ç”Ÿæˆå·¥ä½œæµå›¾å¯è§†åŒ– ==========")
        
        # åˆ›å»ºçœŸå®çš„æœåŠ¡å®ä¾‹ï¼ˆä¸ç”¨ mockï¼‰
        from app.services.digital_human_training_service import DigitalHumanTrainingService
        
        # è¿™é‡Œä¼ å…¥ None å› ä¸ºåªéœ€è¦å›¾çš„ç»“æ„ï¼Œä¸éœ€è¦çœŸå®çš„ä¾èµ–
        service = DigitalHumanTrainingService(
            training_message_repo=None,
            knowledge_extractor=None,
            graph_service=None
        )
        
        # 1. å°è¯•ç”Ÿæˆå›¾ç‰‡
        print("\nğŸ“¸ å°è¯•ç”Ÿæˆå›¾ç‰‡...")
        saved_path = service.save_graph_visualization()
        if saved_path:
            print(f"âœ… å›¾å·²ä¿å­˜åˆ°: {saved_path}")
        
        # 2. å›¾å·²ä¿å­˜ï¼Œæ— éœ€å†ç”Ÿæˆå…¶ä»–æ ¼å¼
        print("\nğŸ’¡ æç¤º: å¯ä»¥æ‰“å¼€ graph_visualizations/training_graph.mmd æŸ¥çœ‹ Mermaid å›¾")
        print("     æˆ–è®¿é—® https://mermaid.live ç²˜è´´å†…å®¹æŸ¥çœ‹æµç¨‹å›¾")
        
        print("\nâœ¨ å·¥ä½œæµå›¾å¯è§†åŒ–æµ‹è¯•å®Œæˆï¼")
        print("=====================================\n")